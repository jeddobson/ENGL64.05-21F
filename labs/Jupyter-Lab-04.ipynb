{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Cultural Analytics</h1><br>\n",
    "<h2>ENGL64.05 / QSS 30.16 Fall 2021</h2>\n",
    "</center>\n",
    "\n",
    "----\n",
    "\n",
    "# Lab 4\n",
    "## Machine Learning and Sentiment Analysis\n",
    "\n",
    " <center><pre>Created: 05/13/2021; Updated 10/27/2021</pre></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with TextBlob's built-in Sentiment Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montfort (pp. 201-204) explains how to use TextBlob's included sentiment analysis tool\n",
    "# In the cell below, use this to evaluate the sentiment and subjectivity of several sample \n",
    "# sections of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try to convert the sentiment score from TextBlob into a four-star system for \n",
    "# determining the degree to which you've found a positive section of text.\n",
    "#\n",
    "# HINT: You can print an emoji (!) with cut-and-paste. If you want to display multiple \n",
    "# characters you can use string multiplication: \"hey\" * 10 will print \"hey\" ten times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python's native storage format for saving serialized\n",
    "# data objects is called \"pickle.\" We can \"dump\" and \"load\"\n",
    "# objects from these files. This file contains a set of Goodreads\n",
    "# reviews pulled from the Web.\n",
    "\n",
    "import pickle\n",
    "reviews = pickle.load(open(\"shared/ENGL64.05-21F/data/book-reviews.pkl\",\"rb\"))\n",
    "print(\"loaded {0} book reviews\".format(len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing:\n",
    "# The reviews contain \"newline\" characters, so let's drop those:\n",
    "reviews = [r.replace(\"\\n\",\"\") for r in reviews]\n",
    "\n",
    "# Do you want to make everything lowercase?\n",
    "# reviews = [r.lower() for r in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the data into training and testing datasets.\n",
    "# The training set will contain the first 500 reviews\n",
    "# and the testing set will be the remainder\n",
    "training_reviews = reviews[:500]\n",
    "testing_reviews = reviews[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here k should be the number of samples that we want to extract\n",
    "# you should select a large enough number to contain both positive\n",
    "# and negative reviews but not too many to make creating your labeled \n",
    "# training set too large.\n",
    "#\n",
    "# We're also displaying the index within the training dataset, which could\n",
    "# potentially be useful if you are not into cut-and-paste in constructing \n",
    "# your labeled data.\n",
    "\n",
    "from random import sample\n",
    "sample(list(enumerate(training_reviews)), k=SOMENUMBERGOESHERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to create a list of tuples in which the first item\n",
    "# is the text of the review and the second a label of either \"pos\"\n",
    "# for a positive review or \"neg\" for a negative review. Both items\n",
    "# in the tuple are strings and need to be quoted. The tuples need\n",
    "# to be separated with commas both within and without the tuple. \n",
    "training_sentiments = [\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify, Show Features, and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TextBlob's wrapper for the NB classifier\n",
    "# and train on your training sentiment data\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "clf = NaiveBayesClassifier(training_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now review the document with help(NaiveBayesClassifier) to learn\n",
    "# how to display the most informative features for your trained\n",
    "# classifier.\n",
    "#\n",
    "# Do you want to go back and change anything from above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run through some selection of your testing data (testing_reviews) and \n",
    "# classify using prob_classify and display the label and optionally the \n",
    "# assigned probability that it is that label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to load saved course reviews from the LayupList\n",
    "old_reviews = json.load(open('data/LayupList/old_reviews.json'))\n",
    "new_reviews = json.load(open('data/LayupList/new_reviews.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the reviews for each department\n",
    "for d in set([r['department'] for r in new_reviews]):\n",
    "    print(d,len([r for r in new_reviews if r['department'] == d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample way to get comments for one department. Select at least three\n",
    "# departments or programs from the above list and assemble lists with these\n",
    "# narrative comments.\n",
    "math_data = [r['comments'] for r in new_reviews if r['department'] == 'MATH']\n",
    "math_data = [' '.join(list(r.values())) for r in math_data if len(r) != 0]\n",
    "math_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you'll need to make training labels (a list that will identify each item vectorized)\n",
    "train_labels = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to vectorize the data. What options should we use? \n",
    "vec = CountVectorizer()\n",
    "\n",
    "# inside the () we need to include our data to vectorize\n",
    "dtm = vec.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shape?\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "clf = SGDClassifier(tol=None,max_iter=1000).fit(dtm, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the most important features to learning classification of these reviews\n",
    "feat_number = 10\n",
    "feature_names = vec.get_feature_names()\n",
    "for i, class_label in enumerate(clf.classes_):\n",
    "    terms = np.argsort(clf.coef_[i])[-feat_number:]\n",
    "    print(\"%s: %s\" % (class_label,\n",
    "                      \", \".join(feature_names[j] for j in terms)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
